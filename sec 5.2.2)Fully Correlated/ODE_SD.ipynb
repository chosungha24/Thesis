{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c5d47ca-b37d-4716-b898-0f1a48f72dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch.nn.utils import spectral_norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0435f00-153f-4caf-9342-7ce6fa9b511c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, neurons, activation, spectral=False):\n",
    "\n",
    "        super(DNN, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.n_layers = len(neurons)\n",
    "        self.dense = {}\n",
    "        self.nn_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.n_layers-1):\n",
    "            if spectral:\n",
    "                self.dense[str(i)] = spectral_norm(nn.Linear(neurons[i], neurons[i+1]))\n",
    "            else:\n",
    "                self.dense[str(i)] = nn.Linear(neurons[i], neurons[i+1])\n",
    "            \n",
    "            if activation==torch.sin:\n",
    "                c = torch.sqrt(torch.tensor(6.))\n",
    "                numerator = torch.sqrt(torch.tensor(neurons[i]).double())\n",
    "                nn.init.uniform_(self.dense[str(i)].weight, a=-c/numerator, b=c/numerator)\n",
    "                nn.init.zeros_(self.dense[str(i)].bias)\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(self.dense[str(i)].weight)\n",
    "                nn.init.zeros_(self.dense[str(i)].bias)                \n",
    "            self.nn_layers.append(self.dense[str(i)])\n",
    "            \n",
    "    def forward(self, *args):\n",
    "        x = torch.cat(args,1)\n",
    "        activation = self.activation\n",
    "        for i in range(self.n_layers-2):\n",
    "            x = activation(self.dense[str(i)](x))\n",
    "        i = self.n_layers-2\n",
    "        return self.dense[str(i)](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b085cfe-fb33-4333-b510-4ea6d168be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "torch.manual_seed(0)\n",
    "\n",
    "dim_x = 1\n",
    "dim_z = 2\n",
    "f_sensors = 41\n",
    "b_sensors = 1\n",
    "B_size=32\n",
    "B_x = torch.randn([dim_x,B_size//2], device=device)\n",
    "B_z = torch.randn([dim_z,B_size//2], device=device)\n",
    "\n",
    "save_path='WGANSN_PCN_SD'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "with open(save_path+'/B_x.pickle', 'wb') as f:\n",
    "    pickle.dump(B_x, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(save_path+'/B_z.pickle', 'wb') as f:\n",
    "    pickle.dump(B_z, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "p=32\n",
    "net_size_ux = [B_size,32,32,p]\n",
    "net_size_uz = [B_size,32,32,p]\n",
    "net_size_D = [f_sensors+b_sensors,64,64,1]\n",
    "\n",
    "def FEx(x):\n",
    "    x_sin = torch.sin(torch.matmul(x,B_x))\n",
    "    x_cos = torch.cos(torch.matmul(x,B_x))\n",
    "    return torch.concat([x_cos,x_sin],-1)\n",
    "\n",
    "def FEz(x):\n",
    "    x_sin = torch.sin(torch.matmul(x,B_z))\n",
    "    x_cos = torch.cos(torch.matmul(x,B_z))\n",
    "    return torch.concat([x_cos,x_sin],-1)\n",
    "\n",
    "acti = torch.sin\n",
    "ux = DNN(net_size_ux, activation=acti).to(device)\n",
    "uz = DNN(net_size_uz, activation=acti).to(device)\n",
    "D = DNN(net_size_D, activation=torch.relu, spectral=True).to(device)\n",
    "\n",
    "def GU(X, Z):\n",
    "    X_FE = FEx(X)\n",
    "    Z = FEz(Z)\n",
    "    outx = acti(ux(X_FE))\n",
    "    outz = uz(Z)\n",
    "    out = torch.matmul(outz,outx.T)\n",
    "    return out\n",
    "\n",
    "def b_tilde(X,Z):\n",
    "    return GU(X,Z)\n",
    "\n",
    "def f_tilde(X,Z):\n",
    "    u = GU(X,Z)\n",
    "    \n",
    "    dummy = torch.ones(u.shape, device=device, requires_grad=True)\n",
    "    tmp = grad(u, X, grad_outputs=dummy, create_graph=True)[0]\n",
    "    u_x = grad(tmp[:,0].sum(), dummy, create_graph=True)[0]\n",
    "    return u_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bbeb4e1-de08-4a3f-982e-70bcc6e53f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 1000\n",
    "x_f = torch.linspace(0,1,f_sensors, device=device, requires_grad=True).reshape(-1,1)\n",
    "x_b = torch.zeros([b_sensors,1], device=device)\n",
    "xi = torch.randn([N_train,2], device=device)\n",
    "\n",
    "cpnt_x = -np.pi*torch.sin(np.pi*x_f)\n",
    "cpnt_x = torch.concat([cpnt_x,-np.pi/2*torch.sin(np.pi/2*x_f)],-1)\n",
    "cpnt_x = torch.concat([cpnt_x,-np.pi/4*torch.sin(np.pi/4*x_f)],-1)\n",
    "cpnt_x = cpnt_x.reshape(1,f_sensors,3)\n",
    "\n",
    "cpnt_xi = torch.ones([N_train,1], device=device)\n",
    "cpnt_xi = torch.concat([cpnt_xi,xi],-1)\n",
    "cpnt_xi = cpnt_xi.reshape(N_train, 1, 3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    f_data = (cpnt_x*cpnt_xi).sum(-1)\n",
    "    b_data = cpnt_xi.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1c2736b-6809-4542-b461-91d1e3fb5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lossD(Z, B, F):\n",
    "    B_gen = b_tilde(x_b, Z)\n",
    "    F_gen = f_tilde(x_f, Z)\n",
    "\n",
    "    Dreal = D(B, F)\n",
    "    Dfake = D(B_gen,F_gen)\n",
    "    lossD = Dreal.mean()-Dfake.mean()\n",
    "    \n",
    "    return -lossD\n",
    "\n",
    "def compute_lossG(Z):\n",
    "    B_gen = b_tilde(x_b, Z)\n",
    "    F_gen = f_tilde(x_f, Z)\n",
    "    \n",
    "    Dfake = D(B_gen,F_gen)\n",
    "    lossG = -Dfake.mean()\n",
    "    return lossG\n",
    "\n",
    "def updateD(Z,B,F):\n",
    "    optimizerD.zero_grad()\n",
    "    lossD = compute_lossD(Z,B,F)\n",
    "    lossD.backward()\n",
    "    optimizerD.step()\n",
    "\n",
    "def updateG(Z):\n",
    "    optimizerG.zero_grad()\n",
    "    lossG = compute_lossG(Z)\n",
    "    lossG.backward()\n",
    "    optimizerG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67d73a37-9058-4540-8e5b-a6b6e263f93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.71177339553833 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "D_params = list(D.parameters())\n",
    "G_params = list(ux.parameters())+list(uz.parameters())\n",
    "optimizerD = torch.optim.RMSprop(D_params, lr=2e-4)\n",
    "optimizerG = torch.optim.RMSprop(G_params, lr=5e-5)\n",
    "\n",
    "num_epochs = 10000\n",
    "st = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    z = torch.randn([N_train,dim_z], device=device)\n",
    "    alpha = torch.randn([N_train,1], device=device)\n",
    "    updateD(z, b_data, f_data)\n",
    "    updateG(z)\n",
    "torch.save(D.state_dict(), save_path+'/paramsD')\n",
    "torch.save(ux.state_dict(), save_path+'/paramsux')\n",
    "torch.save(uz.state_dict(), save_path+'/paramsuz')\n",
    "\n",
    "print(f\"{time.time()-st} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47513a48-33fe-4c16-a2d9-9ac27b80b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "N_test = 20000\n",
    "m_test = 101\n",
    "x_test = torch.linspace(0,1,m_test, device=device).reshape(-1,1)\n",
    "with torch.no_grad():\n",
    "    z_test = torch.randn([N_test,dim_z],device=device)\n",
    "    u_gen = GU(x_test, z_test).cpu()\n",
    "    u_mean, u_std = u_gen.mean(0), u_gen.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d42a52-b383-46b5-ad76-6bd376eb9942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f99de4-c217-4e37-bbe8-9a4a600d38f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c833ff3-986b-4adc-a5ca-5b086c1e4519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c0915c-5889-4554-9adb-e8f70716e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 {os.getpid()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
