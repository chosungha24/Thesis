{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628170594370,
     "user": {
      "displayName": "조성하",
      "photoUrl": "",
      "userId": "09188019178705632892"
     },
     "user_tz": -540
    },
    "id": "xWX2j-0DIh2e"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable#requires_grad\n",
    "from torch.nn.utils import spectral_norm\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy import io\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628170594371,
     "user": {
      "displayName": "조성하",
      "photoUrl": "",
      "userId": "09188019178705632892"
     },
     "user_tz": -540
    },
    "id": "JRyY6LQSIh2h"
   },
   "outputs": [],
   "source": [
    "class MaskedLinear(nn.Linear):\n",
    "    def __init__(self, in_dim, out_dim, mask, Siren=False):\n",
    "        super(MaskedLinear, self).__init__(in_dim, out_dim)\n",
    "        self.mask = mask\n",
    "        if Siren:\n",
    "            c = torch.sqrt(torch.tensor(6., dtype=torch.double))\n",
    "            numerator = torch.sqrt(torch.tensor(in_dim, dtype=torch.double))\n",
    "            nn.init.uniform_(self.weight, a=-c/numerator, b=c/numerator)\n",
    "            nn.init.zeros_(self.bias)\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.weight)\n",
    "            nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.mask = self.mask.to(self.weight.device)\n",
    "        return F.linear(input, self.weight*self.mask, self.bias)\n",
    "        \n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, neurons, activation, spectral=False, Siren=False, num_stack=4, is_mask=False):\n",
    "\n",
    "        super(DNN, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.n_layers = len(neurons)\n",
    "        self.dense = {}\n",
    "        self.nn_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.n_layers-1):\n",
    "            if i>0 and is_mask:\n",
    "                mask = torch.zeros([neurons[i+1], neurons[i]], dtype=torch.double)\n",
    "                len_in = neurons[i]//num_stack\n",
    "                len_out = neurons[i+1]//num_stack\n",
    "                for j in range(num_stack):\n",
    "                    ##neurons 개수가 num stack으로 나누어 떨어지지 않을 수도 있다. 이 경우 마지막을 꽉 채워줘야 함\n",
    "                    if j<num_stack-1:\n",
    "                        mask[j*len_out:(j+1)*len_out,j*len_in:(j+1)*len_in] = 1\n",
    "                    else:\n",
    "                        mask[j*len_out:,j*len_in:] = 1\n",
    "                if spectral:\n",
    "                    self.dense[str(i)] = spectral_norm(MaskedLinear(neurons[i], neurons[i+1], mask=mask, Siren=Siren).double())\n",
    "                else:\n",
    "                    self.dense[str(i)] = MaskedLinear(neurons[i], neurons[i+1], mask=mask, Siren=Siren).double()\n",
    "            else:\n",
    "                if spectral:\n",
    "                    self.dense[str(i)] = spectral_norm(nn.Linear(neurons[i], neurons[i+1]).double())\n",
    "                else:\n",
    "                    self.dense[str(i)] = nn.Linear(neurons[i], neurons[i+1]).double()\n",
    "                    \n",
    "                if Siren:\n",
    "                    c = torch.sqrt(torch.tensor(6.))\n",
    "                    numerator = torch.sqrt(torch.tensor(neurons[i]).double())\n",
    "                    nn.init.uniform_(self.dense[str(i)].weight, a=-c/numerator, b=c/numerator)\n",
    "                    nn.init.zeros_(self.dense[str(i)].bias)\n",
    "                else:\n",
    "                    nn.init.xavier_uniform_(self.dense[str(i)].weight)\n",
    "                    nn.init.zeros_(self.dense[str(i)].bias)\n",
    "            \n",
    "            self.nn_layers.append(self.dense[str(i)])\n",
    "            \n",
    "    def forward(self, *args):\n",
    "        x = torch.cat(args,1)\n",
    "        activation = self.activation\n",
    "        for i in range(self.n_layers-2):\n",
    "            x = activation(self.dense[str(i)](x))\n",
    "        i = self.n_layers-2\n",
    "        return self.dense[str(i)](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1628170595260,
     "user": {
      "displayName": "조성하",
      "photoUrl": "",
      "userId": "09188019178705632892"
     },
     "user_tz": -540
    },
    "id": "vBKVM1BfIh2j"
   },
   "outputs": [],
   "source": [
    "class WGAN_SN():\n",
    "    def __init__(self, n_d, p, n_b, n_t_k, n_t_u, k_sensors, f_sensors, u_sensors, n_tile, n_tile_val, eps_dim, activation, save_path, Siren=False, exp=False,\n",
    "                num_stack=4):\n",
    "        self.exp = exp\n",
    "\n",
    "        self.k_sensors = k_sensors\n",
    "        self.f_sensors = f_sensors\n",
    "        self.u_sensors = u_sensors\n",
    "\n",
    "        self.n_tile = n_tile\n",
    "        self.n_tile_val = n_tile_val\n",
    "        self.eps_dim = eps_dim\n",
    "\n",
    "        self.p = p\n",
    "        self.n_b = n_b\n",
    "        self.n_t_k = n_t_k\n",
    "        self.n_t_u = n_t_u\n",
    "\n",
    "        self.disc = DNN(n_d, activation = activation['disc'], spectral=True)\n",
    "        self.net_b = DNN(n_b, activation = activation['k'], Siren=Siren, is_mask=True, num_stack=num_stack)\n",
    "        self.net_t_k = DNN(n_t_k, activation = activation['k'], Siren=Siren)\n",
    "        self.net_t_u = DNN(n_t_u, activation = activation['u'], Siren=Siren)\n",
    "\n",
    "        param_d = list(self.disc.parameters())\n",
    "        param_g = list(self.net_b.parameters())+ list(self.net_t_k.parameters()) + list(self.net_t_u.parameters())\n",
    "\n",
    "        self.optimizer_d = torch.optim.RMSprop(param_d)\n",
    "        self.optimizer_g = torch.optim.RMSprop(param_g)\n",
    "        \n",
    "        self.mean_error_k = []\n",
    "        self.std_error_k = []\n",
    "        self.mean_error_u = []\n",
    "        self.std_error_u = []\n",
    "        self.n_error = 1000\n",
    "        self.total_epoch =0\n",
    "\n",
    "        self.best_error_k = 1.\n",
    "        self.best_error_u = 1.\n",
    "        \n",
    "        self.path = save_path\n",
    "        if not os.path.isdir(self.path):                                                           \n",
    "            os.mkdir(self.path)\n",
    "        \n",
    "    def train(self, x_k, x_f, x_u, k, f, u, val_res, n_epoch, n_print, lr, n_d=1, n_g=5):\n",
    "        for param_group in self.optimizer_d.param_groups:\n",
    "            param_group['lr'] = lr['d']\n",
    "        for param_group in self.optimizer_g.param_groups:\n",
    "            param_group['lr'] = lr['g']\n",
    "        \n",
    "        st = time.time()\n",
    "        x_k, x_f, x_u, k, f, u = self.to_cuda(x_k, x_f, x_u, k, f, u)\n",
    "        x_f.requires_grad = True\n",
    "        self.to_cuda(self.disc,self.net_t_k,self.net_b,self.net_t_u,model=True)\n",
    "\n",
    "        for epoch in range(n_epoch):\n",
    "            self.train_once(x_k, x_f, x_u, k, f, u, n_d=n_d, n_g=n_g)        \n",
    "            if epoch%self.n_error==0:\n",
    "                if epoch%n_print==0:\n",
    "                    self.record_validation_errors(val_res, epoch, st=st, print_log=True)\n",
    "                else:\n",
    "                    self.record_validation_errors(val_res, epoch)\n",
    "        self.record_validation_errors(val_res, epoch, st=st, print_log=True)\n",
    "        self.to_cpu(self.disc,self.net_t_k,self.net_b,self.net_t_u,model=True)\n",
    "\n",
    "    def compute_loss(self, x_k, x_f, x_u, k, f, u, lamb=0.1, mode=None, uonly=False):\n",
    "        assert mode!=None, 'mode should be determined' \n",
    "\n",
    "        eps = torch.randn([self.n_tile, self.eps_dim], dtype=torch.double)\n",
    "        eps = self.to_cuda(eps)\n",
    "        neural_basis = self.net_b(eps)\n",
    "\n",
    "        #k_tilde\n",
    "        x_k = x_k.T\n",
    "        k_tilde_t = self.net_t_k.activation(self.net_t_k(x_k)).T\n",
    "        k_tilde = torch.matmul(neural_basis, k_tilde_t)\n",
    "        if self.exp:\n",
    "            k_tilde = torch.exp(k_tilde) + 1/2\n",
    "\n",
    "        #f_tilde\n",
    "        #dummy와 for문은 1e-14정도의 error가 생긴다\n",
    "        x_f = x_f.T\n",
    "        with torch.no_grad():\n",
    "            k_f_t = self.net_t_k.activation(self.net_t_k(x_f)).T\n",
    "            k_f = torch.matmul(neural_basis.detach(), k_f_t)\n",
    "            if self.exp:\n",
    "                k_f = torch.exp(k_f) + 1/2\n",
    "\n",
    "        u_f_t = self.net_t_u.activation(self.net_t_u(x_f)[:,:self.p]).T\n",
    "        dummy = torch.ones(u_f_t.shape, dtype=torch.double, device=u_f_t.device, requires_grad=True)\n",
    "        grad_tmp = grad(u_f_t, x_f, grad_outputs=dummy, create_graph=True)[0]\n",
    "        u_f_t_x = grad(grad_tmp[:,0].sum(), dummy, create_graph=True)[0]\n",
    "        u_f_t_y = grad(grad_tmp[:,1].sum(), dummy, create_graph=True)[0]\n",
    "\n",
    "        \n",
    "        tau_f_t = self.net_t_u.activation(self.net_t_u(x_f)[:,self.p:]).T\n",
    "        dummy = torch.ones(tau_f_t.shape, dtype=torch.double, device=tau_f_t.device, requires_grad=True)\n",
    "        grad_tmp = grad(tau_f_t, x_f, grad_outputs=dummy, create_graph=True)[0]\n",
    "        tau1_f_t_x = grad(grad_tmp[:,0].sum(), dummy, create_graph=True)[0][:self.p]\n",
    "        tau2_f_t_y = grad(grad_tmp[:,1].sum(), dummy, create_graph=True)[0][self.p:]\n",
    "        \n",
    "\n",
    "        u_f_ = torch.matmul(neural_basis, u_f_t)\n",
    "        u_f_x_ = torch.matmul(neural_basis, u_f_t_x)\n",
    "        u_f_y_ = torch.matmul(neural_basis, u_f_t_y)\n",
    "        u_f = (1-(x_f[:,:1].T)**2)*(1-(x_f[:,1:].T)**2)*u_f_\n",
    "        u_f_x = -2*x_f[:,:1].T*(1-(x_f[:,1:].T)**2)*u_f_ + (1-(x_f[:,:1].T)**2)*(1-(x_f[:,1:].T)**2)*u_f_x_\n",
    "        u_f_y = -2*x_f[:,1:].T*(1-(x_f[:,:1].T)**2)*u_f_ + (1-(x_f[:,:1].T)**2)*(1-(x_f[:,1:].T)**2)*u_f_y_\n",
    "\n",
    "        tau1_f = torch.matmul(neural_basis, tau_f_t[:self.p,:])\n",
    "        tau2_f = torch.matmul(neural_basis, tau_f_t[self.p:,:])\n",
    "        tau1_f_x = torch.matmul(neural_basis, tau1_f_t_x)\n",
    "        tau2_f_y = torch.matmul(neural_basis, tau2_f_t_y)\n",
    "\n",
    "        #####tau1과 tau2를 따로 해야하나?\n",
    "        tau_tilde = torch.cat([k_f*u_f_x + tau1_f, k_f*u_f_y + tau2_f], 1)\n",
    "        f_tilde = tau1_f_x + tau2_f_y\n",
    "\n",
    "        logit_fake = self.disc(k_tilde, tau_tilde, f_tilde)\n",
    "        logit_real = self.disc(k, torch.zeros_like(tau_tilde), f)\n",
    "\n",
    "        if mode=='d':\n",
    "            #discriminator는 real을 1로, fake를 0으로 가게하려고 한다.\n",
    "            loss_fake = torch.mean(logit_fake)\n",
    "            loss_real = torch.mean(logit_real)\n",
    "\n",
    "            loss_d = -loss_real + loss_fake\n",
    "            return loss_d\n",
    "        \n",
    "        if mode=='g':            \n",
    "            loss_fake = torch.mean(logit_fake)\n",
    "            loss_g = -loss_fake\n",
    "            \n",
    "            return loss_g\n",
    "\n",
    "    def train_once(self, x_k, x_f, x_u, k, f, u, n_d=1, n_g=1):\n",
    "        for epoch_d in range(n_d):\n",
    "            self.optimizer_d.zero_grad()\n",
    "            loss_d = self.compute_loss(x_k, x_f, x_u, k, f, u, mode='d')\n",
    "            loss_d.backward()#retain_graph=True)\n",
    "            self.optimizer_d.step()\n",
    "            \n",
    "        for epoch_g in range(n_g):\n",
    "            self.optimizer_g.zero_grad()\n",
    "            loss_g = self.compute_loss(x_k, x_f, x_u, k, f, u, mode='g')\n",
    "            loss_g.backward()#retain_graph=True)\n",
    "            self.optimizer_g.step()\n",
    "\n",
    "    def record_validation_errors(self, val_res, epoch, st=None, print_log=False):\n",
    "        x_k = val_res['x_k']\n",
    "        x_f = val_res['x_f']\n",
    "        x_f.requires_grad=True\n",
    "        k_mean_val, k_std_val = val_res['k_mean'], val_res['k_std']\n",
    "        f = val_res['f']\n",
    "\n",
    "        self.total_epoch += self.n_error\n",
    "        with torch.no_grad():\n",
    "            _, k_mean_pred, k_std_pred = self.predict_k_NC(x_k, self.n_tile_val)\n",
    "        _, f_mean_pred, f_std_pred = self.predict_f_NC(x_f, self.n_tile_val)\n",
    "        \n",
    "        f_mean_pred, f_std_pred = f_mean_pred.detach(), f_std_pred.detach()  \n",
    "        k_mean_pred, k_std_pred, f_mean_pred, f_std_pred = self.to_cpu(k_mean_pred, k_std_pred, f_mean_pred, f_std_pred)\n",
    "        \n",
    "        er_mean_k = torch.norm(k_mean_pred-k_mean_val)/torch.norm(k_mean_val)\n",
    "        er_std_k = torch.norm(k_std_pred-k_std_val)/torch.norm(k_std_val)\n",
    "        er_mean_f = torch.norm(f_mean_pred-f)/torch.norm(f)\n",
    "        er_std_f = torch.norm(f_std_pred)/torch.numel(f_std_pred)\n",
    "        er_mean_u = er_mean_f\n",
    "        er_std_u = er_std_f\n",
    "        self.mean_error_k.append(er_mean_k)\n",
    "        self.std_error_k.append(er_std_k)\n",
    "        self.mean_error_u.append(er_mean_u)\n",
    "        self.std_error_u.append(er_std_u)\n",
    "        \n",
    "        if er_mean_k + er_std_k<self.best_error_k :\n",
    "            self.best_error_k = er_mean_k + er_std_k\n",
    "            torch.save(self.net_b.state_dict(), self.path+'/net_b_k')\n",
    "            torch.save(self.net_t_k.state_dict(), self.path+'/net_t_k')\n",
    "            print('k is updated, Epoch:%s loss_k:[%.3e, %.3e]'%(epoch, er_mean_k, er_std_k))\n",
    "\n",
    "        if er_mean_u + er_std_u<self.best_error_u :\n",
    "            self.best_error_u = er_mean_u + er_std_u\n",
    "            torch.save(self.net_b.state_dict(), self.path+'/net_b_u')\n",
    "            torch.save(self.net_t_u.state_dict(), self.path+'/net_t_u')\n",
    "            print('u is updated, Epoch:%s loss_u:[%.3e, %.3e]'%(epoch, er_mean_u, er_std_u))        \n",
    "\n",
    "        if print_log:\n",
    "            print(f'[Epoch {epoch}] loss_k:[{er_mean_k:.3e}, {er_std_k:.3e}], loss_u:[{er_mean_u:.3e}, {er_std_u:.3e}], {(time.time()-st):.3f} seconds went by')\n",
    "            validation_loss = {}\n",
    "            validation_loss['total_epoch'] = self.total_epoch\n",
    "            validation_loss['n_loss'] = self.n_error\n",
    "            validation_loss['mean_loss_k'] = self.mean_error_k\n",
    "            validation_loss['std_loss_k'] = self.std_error_k\n",
    "            validation_loss['mean_loss_u'] = self.mean_error_u\n",
    "            validation_loss['std_loss_u'] = self.std_error_u\n",
    "            torch.save(validation_loss, self.path+'/validation_error')\n",
    "\n",
    "    def predict_k_NC(self, X, n_tile):\n",
    "        n_sensors = X.shape[1]\n",
    "\n",
    "        X = X.T.to(next(model.net_t_k.parameters()).device)\n",
    "        eps = torch.randn([n_tile, self.eps_dim], dtype=torch.double).to(next(model.net_t_k.parameters()).device)\n",
    "        k_pred_t = self.net_t_k.activation(self.net_t_k(X)).T\n",
    "        k_pred_b = self.net_b(eps)\n",
    "        k_pred = torch.matmul(k_pred_b, k_pred_t).detach()\n",
    "        if self.exp:\n",
    "            k_pred = torch.exp(k_pred) + 1/2\n",
    "\n",
    "        k_mean, k_std = k_pred.mean(0), k_pred.std(0)\n",
    "        return k_pred, k_mean, k_std\n",
    "\n",
    "    def predict_u_NC(self, X, n_tile):\n",
    "        n_sensors = X.shape[1]\n",
    "        \n",
    "        X = X.T.to(next(model.net_t_u.parameters()).device)\n",
    "        eps = torch.randn([n_tile, self.eps_dim], dtype=torch.double).to(next(model.net_t_u.parameters()).device)\n",
    "        u_pred_t = self.net_t_u.activation(self.net_t_u(X)[:,:self.p]).T\n",
    "        u_pred_b = self.net_b(eps)\n",
    "        u_pred = (torch.matmul(u_pred_b, u_pred_t)*(1-(X[:,:1].T)**2)*(1-(X[:,1:].T)**2)).detach()\n",
    "\n",
    "        u_mean, u_std = u_pred.mean(0), u_pred.std(0)\n",
    "        return u_pred, u_mean, u_std\n",
    "    \n",
    "    def predict_f_NC(self, X, n_tile):\n",
    "        n_sensors = X.shape[1]\n",
    "\n",
    "        X = X.T.to(next(model.net_t_k.parameters()).device)\n",
    "        eps = torch.randn([n_tile, self.eps_dim], dtype=torch.double).to(next(model.net_t_k.parameters()).device)\n",
    "        \n",
    "        k_pred_t = self.net_t_k.activation(self.net_t_k(X)).T\n",
    "        k_pred_b = self.net_b(eps)\n",
    "        k_pred = torch.matmul(k_pred_b, k_pred_t)\n",
    "        if self.exp:\n",
    "            k_pred = torch.exp(k_pred) + 1/2\n",
    "            \n",
    "        dummy = torch.ones(k_pred.shape, dtype=torch.double, device=k_pred.device, requires_grad=True)\n",
    "        grad_tmp = grad(k_pred, X, grad_outputs=dummy, create_graph=True)[0]\n",
    "        k_x = grad(grad_tmp[:,0].sum(), dummy, retain_graph=True)[0]\n",
    "        k_y = grad(grad_tmp[:,1].sum(), dummy)[0]\n",
    "        \n",
    "        ##\n",
    "        u_pred_b = self.net_b(eps)\n",
    "        u_pred_t = self.net_t_u.activation(self.net_t_u(X)[:,:self.p]).T\n",
    "        \n",
    "        dummy = torch.ones(u_pred_t.shape, dtype=torch.double, device=u_pred_t.device, requires_grad=True)\n",
    "        grad_tmp = grad(u_pred_t, X, grad_outputs=dummy, create_graph=True)[0]\n",
    "        u_pred_t_x = grad(grad_tmp[:,0].sum(), dummy, create_graph=True)[0]\n",
    "        u_pred_t_y = grad(grad_tmp[:,1].sum(), dummy, create_graph=True)[0]\n",
    "        \n",
    "        grad_x = grad(u_pred_t_x, X, grad_outputs=dummy, create_graph=True)[0]\n",
    "        grad_y = grad(u_pred_t_y, X, grad_outputs=dummy, create_graph=True)[0]\n",
    "        u_pred_t_xx = grad(grad_x[:,0].sum(), dummy)[0]\n",
    "        u_pred_t_yy = grad(grad_y[:,1].sum(), dummy)[0]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            u_pred_ = torch.matmul(u_pred_b, u_pred_t).detach()\n",
    "            u_x_ = torch.matmul(u_pred_b, u_pred_t_x).detach()\n",
    "            u_y_ = torch.matmul(u_pred_b, u_pred_t_y).detach()\n",
    "            u_xx_ = torch.matmul(u_pred_b, u_pred_t_xx).detach()\n",
    "            u_yy_ = torch.matmul(u_pred_b, u_pred_t_yy).detach()\n",
    "            \n",
    "            x = X[:,:1].T\n",
    "            y = X[:,1:].T\n",
    "            u_x = -2*x*u_pred_ + (1-x**2)*u_x_\n",
    "            u_y = -2*y*u_pred_ + (1-y**2)*u_y_\n",
    "            u_xx = -2*u_pred_ - 4*x*u_x_ + (1-x**2)*u_xx_\n",
    "            u_yy = -2*u_pred_ - 4*y*u_y_ + (1-y**2)*u_yy_\n",
    "            u_x, u_xx, u_y, u_yy = (1-y**2)*u_x, (1-y**2)*u_xx, (1-x**2)*u_y, (1-x**2)*u_yy\n",
    "        \n",
    "            f_pred = -(k_x*u_x + k_pred*u_xx + k_y*u_y + k_pred*u_yy)\n",
    "            f_mean, f_std = f_pred.mean(0), f_pred.std(0)\n",
    "            \n",
    "        return f_pred, f_mean, f_std\n",
    "\n",
    "    def to_cuda(self, *args, model=False):\n",
    "        if model:\n",
    "            for comp in args:\n",
    "                comp.cuda()\n",
    "        else:\n",
    "            res = []\n",
    "            for comp in args:\n",
    "                res.append(comp.cuda())\n",
    "            if len(res)==1:\n",
    "                res = res[0]\n",
    "            return res\n",
    "\n",
    "    def to_cpu(self, *args, model=False):\n",
    "        if model:\n",
    "            for comp in args:\n",
    "                comp.cpu()\n",
    "        else:\n",
    "            res = []\n",
    "            for comp in args:\n",
    "                res.append(comp.cpu())\n",
    "            if len(res)==1:\n",
    "                res = res[0]\n",
    "            return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1628170595260,
     "user": {
      "displayName": "조성하",
      "photoUrl": "",
      "userId": "09188019178705632892"
     },
     "user_tz": -540
    },
    "id": "GcL4bSzSIh2l"
   },
   "outputs": [],
   "source": [
    "def to_torch(*args):\n",
    "    res = []\n",
    "    for comp in args:\n",
    "        res.append(torch.from_numpy(comp).double())\n",
    "    if len(res)==1:\n",
    "        res = res[0]\n",
    "    return res\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "X_dim=2\n",
    "u_dim=1#u_dim이 곧 k_dim\n",
    "lc = 1.0\n",
    "sigma = 0.3\n",
    "\n",
    "k_sensors = 121\n",
    "f_sensors = 121\n",
    "u_sensors = 2\n",
    "n_tile = 8000\n",
    "eps_dim = 3\n",
    "n_tile_val = 400\n",
    "\n",
    "##training data\n",
    "with open(f'train_data_2d_{lc}lc_{sigma}sigma_{k_sensors}ksensors_{f_sensors}fsensors.pkl', 'rb') as ff:\n",
    "    train_data = pickle.load(ff)\n",
    "x_k = train_data['x_k']\n",
    "x_f = train_data['x_f']\n",
    "x_u = train_data['x_u']\n",
    "k = train_data['k'][:n_tile]\n",
    "f = train_data['f']\n",
    "u = train_data['u']\n",
    "\n",
    "x_k, x_f, x_u, k, f, u = to_torch(x_k, x_f, x_u, k, f, u)\n",
    "f = f.repeat([n_tile, 1])\n",
    "u = u.repeat([n_tile, 1])\n",
    "\n",
    "n_d = [k_sensors+3*f_sensors, 128, 128, 128, 128, 1]\n",
    "\n",
    "p = 64\n",
    "n_b = [eps_dim, 64, 64, p]\n",
    "n_t_k = [X_dim, 64, 64, p]\n",
    "n_t_u = [X_dim, 64, 64, (X_dim+1)*p]\n",
    "\n",
    "val_data = {}\n",
    "val_data['x_k']=x_k\n",
    "val_data['k_mean'], val_data['k_std']=k.mean(0), k.std(0)\n",
    "val_data['x_f']=x_f\n",
    "val_data['f']=f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] loss_k:[1.825e+00, 1.895e+01], loss_u:[1.821e+00, 4.645e+00], 3.554 seconds went by\n",
      "k is updated, Epoch:2000 loss_k:[2.935e-02, 3.875e-01]\n",
      "u is updated, Epoch:2000 loss_u:[1.364e-01, 3.712e-01]\n",
      "k is updated, Epoch:3000 loss_k:[2.509e-02, 3.439e-01]\n",
      "u is updated, Epoch:3000 loss_u:[1.216e-01, 2.336e-01]\n",
      "u is updated, Epoch:4000 loss_u:[8.879e-02, 1.456e-01]\n",
      "u is updated, Epoch:5000 loss_u:[8.587e-02, 1.284e-01]\n",
      "[Epoch 5000] loss_k:[1.656e-02, 5.580e-01], loss_u:[8.587e-02, 1.284e-01], 159.125 seconds went by\n",
      "u is updated, Epoch:6000 loss_u:[7.717e-02, 1.146e-01]\n",
      "u is updated, Epoch:7000 loss_u:[7.577e-02, 8.837e-02]\n",
      "u is updated, Epoch:8000 loss_u:[6.813e-02, 7.668e-02]\n",
      "u is updated, Epoch:9000 loss_u:[6.560e-02, 7.257e-02]\n",
      "u is updated, Epoch:10000 loss_u:[6.354e-02, 6.566e-02]\n",
      "[Epoch 10000] loss_k:[1.589e-02, 7.527e-01], loss_u:[6.354e-02, 6.566e-02], 315.718 seconds went by\n",
      "u is updated, Epoch:11000 loss_u:[6.018e-02, 5.197e-02]\n",
      "u is updated, Epoch:12000 loss_u:[5.784e-02, 5.169e-02]\n",
      "u is updated, Epoch:13000 loss_u:[5.611e-02, 4.941e-02]\n",
      "u is updated, Epoch:14000 loss_u:[5.410e-02, 4.636e-02]\n",
      "u is updated, Epoch:15000 loss_u:[5.334e-02, 4.206e-02]\n",
      "[Epoch 15000] loss_k:[1.395e-02, 7.771e-01], loss_u:[5.334e-02, 4.206e-02], 472.442 seconds went by\n",
      "k is updated, Epoch:17000 loss_k:[1.094e-02, 3.359e-01]\n",
      "u is updated, Epoch:17000 loss_u:[4.732e-02, 4.758e-02]\n",
      "k is updated, Epoch:18000 loss_k:[1.683e-02, 3.292e-01]\n",
      "k is updated, Epoch:19000 loss_k:[1.159e-02, 3.158e-01]\n",
      "u is updated, Epoch:19000 loss_u:[4.683e-02, 4.276e-02]\n",
      "k is updated, Epoch:20000 loss_k:[9.115e-03, 2.870e-01]\n",
      "u is updated, Epoch:20000 loss_u:[4.657e-02, 4.184e-02]\n",
      "[Epoch 20000] loss_k:[9.115e-03, 2.870e-01], loss_u:[4.657e-02, 4.184e-02], 628.251 seconds went by\n",
      "u is updated, Epoch:21000 loss_u:[4.497e-02, 3.885e-02]\n",
      "u is updated, Epoch:22000 loss_u:[4.640e-02, 3.460e-02]\n",
      "u is updated, Epoch:23000 loss_u:[4.027e-02, 3.308e-02]\n",
      "[Epoch 25000] loss_k:[1.706e-02, 4.066e-01], loss_u:[4.099e-02, 3.526e-02], 774.110 seconds went by\n",
      "u is updated, Epoch:26000 loss_u:[4.059e-02, 2.983e-02]\n",
      "u is updated, Epoch:29000 loss_u:[3.694e-02, 3.013e-02]\n",
      "[Epoch 30000] loss_k:[1.291e-02, 3.654e-01], loss_u:[4.094e-02, 2.918e-02], 919.608 seconds went by\n",
      "u is updated, Epoch:33000 loss_u:[3.904e-02, 2.730e-02]\n",
      "[Epoch 35000] loss_k:[9.232e-03, 3.088e-01], loss_u:[4.094e-02, 2.676e-02], 1064.845 seconds went by\n",
      "u is updated, Epoch:37000 loss_u:[3.785e-02, 2.726e-02]\n",
      "u is updated, Epoch:38000 loss_u:[3.756e-02, 2.699e-02]\n",
      "[Epoch 40000] loss_k:[8.716e-03, 3.773e-01], loss_u:[3.904e-02, 2.594e-02], 1215.199 seconds went by\n",
      "u is updated, Epoch:41000 loss_u:[3.571e-02, 2.407e-02]\n",
      "u is updated, Epoch:44000 loss_u:[3.520e-02, 2.236e-02]\n",
      "[Epoch 45000] loss_k:[7.548e-03, 3.511e-01], loss_u:[3.736e-02, 2.416e-02], 1369.181 seconds went by\n",
      "k is updated, Epoch:48000 loss_k:[1.367e-02, 2.594e-01]\n",
      "k is updated, Epoch:49000 loss_k:[1.372e-02, 2.450e-01]\n",
      "k is updated, Epoch:50000 loss_k:[1.265e-02, 2.084e-01]\n",
      "[Epoch 50000] loss_k:[1.265e-02, 2.084e-01], loss_u:[4.421e-02, 2.995e-02], 1518.204 seconds went by\n",
      "k is updated, Epoch:53000 loss_k:[1.478e-02, 1.694e-01]\n",
      "[Epoch 55000] loss_k:[2.230e-02, 1.845e-01], loss_u:[3.956e-02, 3.311e-02], 1663.755 seconds went by\n",
      "k is updated, Epoch:56000 loss_k:[9.272e-03, 1.628e-01]\n",
      "k is updated, Epoch:57000 loss_k:[1.702e-02, 1.526e-01]\n",
      "[Epoch 60000] loss_k:[8.812e-03, 1.743e-01], loss_u:[4.323e-02, 2.789e-02], 1814.648 seconds went by\n",
      "[Epoch 65000] loss_k:[1.668e-02, 1.989e-01], loss_u:[3.900e-02, 2.876e-02], 1971.061 seconds went by\n",
      "[Epoch 70000] loss_k:[8.866e-03, 1.828e-01], loss_u:[3.860e-02, 2.597e-02], 2127.200 seconds went by\n",
      "[Epoch 75000] loss_k:[1.324e-02, 2.722e-01], loss_u:[4.464e-02, 3.936e-02], 2283.380 seconds went by\n",
      "[Epoch 80000] loss_k:[2.137e-02, 1.957e-01], loss_u:[4.291e-02, 3.023e-02], 2440.359 seconds went by\n",
      "k is updated, Epoch:84000 loss_k:[1.758e-02, 1.517e-01]\n",
      "[Epoch 85000] loss_k:[1.946e-02, 1.792e-01], loss_u:[3.847e-02, 3.371e-02], 2586.112 seconds went by\n",
      "[Epoch 90000] loss_k:[1.793e-02, 2.024e-01], loss_u:[3.434e-02, 2.605e-02], 2731.249 seconds went by\n",
      "[Epoch 95000] loss_k:[1.395e-02, 1.853e-01], loss_u:[3.863e-02, 2.487e-02], 2876.768 seconds went by\n",
      "u is updated, Epoch:98000 loss_u:[3.124e-02, 2.447e-02]\n",
      "[Epoch 99999] loss_k:[1.306e-02, 2.003e-01], loss_u:[3.350e-02, 2.871e-02], 3026.730 seconds went by\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "activation={'disc':F.relu, 'k':torch.sin, 'u':torch.sin}\n",
    "save_path = f'SPDE_NC_onedisc'\n",
    "model = WGAN_SN(n_d, p, n_b, n_t_k, n_t_u, k_sensors, f_sensors, u_sensors, n_tile, n_tile_val, eps_dim, activation=activation, save_path=save_path, \n",
    "                Siren=True, exp=True, num_stack=4)\n",
    "model.train(x_k, x_f, x_u, k, f, u, val_data, n_epoch=100000,lr={'d':2e-4,'g':5e-5}, n_print=5000, n_d=1, n_g=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-gc7cgUsZH7"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model.to_cpu(model.net_b,model.net_t_k,model.net_t_u, model=True)\n",
    "\n",
    "##test data\n",
    "with open(f'test_data_2d_{lc}lc_{sigma}sigma_origin.pkl', 'rb') as ff:\n",
    "    test_data = pickle.load(ff)\n",
    "for key in test_data.keys():\n",
    "    test_data[key] = to_torch(test_data[key])\n",
    "    \n",
    "x_val = test_data['x']\n",
    "k_mean_ref, k_std_ref = test_data['k_mean'], test_data['k_std']\n",
    "u_mean_ref, u_std_ref = test_data['u_mean'], test_data['u_std']\n",
    "\n",
    "fig_QoI, axes_QoI = plt.subplots(2,2, figsize=(12,6))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes_QoI[i,j] = fig_QoI.add_subplot(2, 2, 2*i+j+1, projection='3d')\n",
    "with torch.no_grad():\n",
    "    _, k_mean, k_std = model.predict_k_NC(x_val, n_tile_val)\n",
    "    _, u_mean, u_std = model.predict_u_NC(x_val, n_tile_val)\n",
    "\n",
    "er_mean_k = torch.norm(k_mean-k_mean_ref)/torch.norm(k_mean_ref)\n",
    "er_std_k = torch.norm(k_std-k_std_ref)/torch.norm(k_std_ref)\n",
    "er_mean_u = torch.norm(u_mean-u_mean_ref)/torch.norm(u_mean_ref)\n",
    "er_std_f = torch.norm(u_std-u_std_ref)/torch.norm(u_std_ref)\n",
    "print(f'DON model error: {er_mean_k:.3e}, {er_std_k:.3e}, {er_mean_u:.3e}, {er_std_f:.3e}')\n",
    "\n",
    "\n",
    "axes_QoI[0,0].plot_trisurf(x_val[0], x_val[1], k_mean, linewidth=0.2, antialiased=True, label='GAN')\n",
    "axes_QoI[0,1].plot_trisurf(x_val[0], x_val[1], k_std, linewidth=0.2, antialiased=True, label='GAN')\n",
    "axes_QoI[1,0].plot_trisurf(x_val[0], x_val[1], u_mean, linewidth=0.2, antialiased=True, label='GAN')\n",
    "axes_QoI[1,1].plot_trisurf(x_val[0], x_val[1], u_std, linewidth=0.2, antialiased=True, label='GAN')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "axes_QoI[0,0].plot_trisurf(x_val[0], x_val[1], k_mean_ref, linewidth=0.2, antialiased=True, label='reference')\n",
    "axes_QoI[0,1].plot_trisurf(x_val[0], x_val[1], k_std_ref, linewidth=0.2, antialiased=True, label='reference')\n",
    "axes_QoI[1,0].plot_trisurf(x_val[0], x_val[1], u_mean_ref, linewidth=0.2, antialiased=True, label='reference')\n",
    "axes_QoI[1,1].plot_trisurf(x_val[0], x_val[1], u_std_ref, linewidth=0.2, antialiased=True, label='reference')\n",
    "\n",
    "fig_QoI.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_QoI, axes_QoI = plt.subplots(2, 2, figsize=(12, 6))\n",
    "\n",
    "start = 101*25\n",
    "end = 101*26\n",
    "axes_QoI[0,0].plot(x_val[1,start:end],k_mean[start:end], label='GAN')\n",
    "axes_QoI[0,1].plot(x_val[1,start:end],k_std[start:end], label='GAN')\n",
    "axes_QoI[1,0].plot(x_val[1,start:end],u_mean[start:end], label='GAN')\n",
    "axes_QoI[1,1].plot(x_val[1,start:end],u_std[start:end], label='GAN')\n",
    "\n",
    "er_mean_k = torch.norm(k_mean-k_mean_ref)/torch.norm(k_mean_ref)\n",
    "er_std_k = torch.norm(k_std-k_std_ref)/torch.norm(k_std_ref)\n",
    "er_mean_u = torch.norm(u_mean-u_mean_ref)/torch.norm(u_mean_ref)\n",
    "er_std_u = torch.norm(u_std-u_std_ref)/torch.norm(u_std_ref)\n",
    "print(f'2d NC: {er_mean_k:.3e}, {er_std_k:.3e}, {er_mean_u:.3e}, {er_std_u:.3e}')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "axes_QoI[0,0].plot(x_val[1,start:end],k_mean_ref[start:end], label='reference')\n",
    "axes_QoI[0,1].plot(x_val[1,start:end],k_std_ref[start:end], label='reference')\n",
    "axes_QoI[1,0].plot(x_val[1,start:end],u_mean_ref[start:end], label='reference')\n",
    "axes_QoI[1,1].plot(x_val[1,start:end],u_std_ref[start:end], label='reference')\n",
    "\n",
    "axes_QoI[0].set_title('mean at x=-0.5')\n",
    "axes_QoI[1].set_title('standard deviation at x=-0.5')\n",
    "axes_QoI[0].set_xlabel('y')\n",
    "axes_QoI[1].set_xlabel('y')\n",
    "# fig_QoI.savefig('SPDE_2d_QoI_x=-0.5.pdf')\n",
    "fig_QoI.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeyNx13-N0s-"
   },
   "outputs": [],
   "source": [
    "#version2_2 = [*, 128, 128, *]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SPDE_NC_strong_share_b_tau_branched_원본.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
